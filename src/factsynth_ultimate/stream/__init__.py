"""Utilities for streaming fact synthesis results over multiple transports."""

from __future__ import annotations

import asyncio
import textwrap
from collections.abc import AsyncIterator, Awaitable, Callable
from dataclasses import dataclass

from facts import FactPipeline

from factsynth_ultimate.core.tracing import record_exception, set_span_attributes, start_span

IsDisconnected = Callable[[], Awaitable[bool]]


@dataclass(slots=True)
class FactStreamChunk:
    """Single chunk of facts emitted by :func:`stream_facts`."""

    index: int
    text: str


def _chunk_text(text: str, *, limit: int) -> list[str]:
    """Split ``text`` into whitespace-aware chunks up to ``limit`` characters."""

    if limit <= 0:
        raise ValueError("limit must be positive")

    normalized = " ".join(text.split())
    if not normalized:
        return []

    return textwrap.wrap(
        normalized,
        width=limit,
        break_long_words=False,
        break_on_hyphens=False,
    )


async def stream_facts(
    pipeline: FactPipeline,
    query: str,
    *,
    chunk_size: int = 128,
    start_at: int = 0,
    delay: float = 0.0,
    is_disconnected: IsDisconnected | None = None,
) -> AsyncIterator[FactStreamChunk]:
    """Yield fact chunks generated by ``pipeline`` for ``query``.

    Args:
        pipeline: The :class:`FactPipeline` instance providing synthesized facts.
        query: User supplied query text.
        chunk_size: Maximum size (in characters) for each yielded chunk.
        start_at: Index of the first chunk to yield, enabling resumable streams.
        delay: Optional delay applied between yielded chunks for rate control.
        is_disconnected: Optional awaitable returning ``True`` when the
            consumer has disconnected.

    Yields:
        :class:`FactStreamChunk` objects ordered by ``index``.
    """

    start_index = max(0, int(start_at))
    sleep_delay = max(0.0, float(delay))
    emitted = 0

    with start_span("facts.stream_facts") as span:
        set_span_attributes(
            span,
            {
                "factsynth.stream.chunk_size": chunk_size,
                "factsynth.stream.start_at": start_index,
                "factsynth.stream.query.length": len(query or ""),
            },
        )
        try:
            result = pipeline.run(query)
            chunks = _chunk_text(result, limit=chunk_size)
            total_chunks = len(chunks)
            set_span_attributes(
                span,
                {"factsynth.stream.total_chunks": total_chunks},
            )
            if not chunks or start_index >= total_chunks:
                return

            first_chunk = True
            for index in range(start_index, total_chunks):
                if is_disconnected and await is_disconnected():
                    break
                if not first_chunk and sleep_delay > 0:
                    await asyncio.sleep(sleep_delay)
                    if is_disconnected and await is_disconnected():
                        break
                yield FactStreamChunk(index=index, text=chunks[index])
                emitted += 1
                first_chunk = False
        except Exception as exc:  # pragma: no cover - defensive guard
            record_exception(span, exc)
            raise
        finally:
            set_span_attributes(
                span,
                {"factsynth.stream.emitted": emitted},
            )


__all__ = ["FactStreamChunk", "stream_facts"]
