from __future__ import annotations

"""String-cleaning helpers used across FactSynth Ultimate.

The functions below normalise text, strip unwanted formatting and enforce exact
word counts.  They are intentionally lightweight so they can be re-used by the
API, CLI and orchestration pipeline without pulling in heavy dependencies.
"""

import regex as re

from .tokenization import normalize, tokenize

# Basic emoji range covering the Misc Symbols & Pictographs block.
EMOJI_RANGE = (0x1F300, 0x1FAFF)
# Markdown-style headings (``#``, ``===`` or ``---``) at line start.
HEAD_PAT = re.compile(r"^\s*(#+|={3,}|-{3,})", re.M)
# Bulleted or numbered list markers.
LIST_PAT = re.compile(r"^\s*([\-*‚Ä¢¬∑]|\d+\.)\s+", re.M)
# Any run of whitespace that should collapse to a single space.
SPACE_PAT = re.compile(r"\s+")


def has_emoji(s: str) -> bool:
    """Check if ``s`` contains any emoji characters.

    Args:
        s: Text to inspect.

    Returns:
        True if any character's Unicode code point falls within ``EMOJI_RANGE``,
        otherwise False.

    Edge cases:
        Handles empty strings and only detects emojis whose code points are between
        0x1F300 and 0x1FAFF. Newly introduced emojis outside this range will be
        ignored.

    Example:
        ``has_emoji("hi üôÇ")`` ‚Üí ``True``
    """
    return any(EMOJI_RANGE[0] <= ord(ch) <= EMOJI_RANGE[1] for ch in s)


def sanitize(
    text: str,
    *,
    forbid_questions: bool = True,
    forbid_headings: bool = True,
    forbid_lists: bool = True,
    forbid_emojis: bool = True,
) -> str:
    """Normalize and scrub free-form text.

    Args:
        text: Raw text that may contain markup or unwanted characters.
        forbid_questions: When True, replaces question marks with periods.
        forbid_headings: When True, strips Markdown-style heading markers.
        forbid_lists: When True, removes common list markers.
        forbid_emojis: When True, drops emoji characters detected by :func:`has_emoji`.

    Returns:
        Cleaned text with collapsed whitespace and no leading or trailing spaces.

    Edge cases:
        - Whitespace is normalized to single spaces and trimmed.
        - Removal of headings or lists may yield an empty string.
        - Only emojis recognized by :func:`has_emoji` are removed; others remain.

    Example:
        ``sanitize("# Title\n1. item?")`` ‚Üí ``"Title item."``
    """
    t = normalize(text)
    if forbid_questions:
        t = t.replace("?", ".")
    t = SPACE_PAT.sub(" ", t).strip()
    if forbid_headings and HEAD_PAT.search(t):
        t = HEAD_PAT.sub("", t)
    if forbid_lists and LIST_PAT.search(t):
        t = LIST_PAT.sub("", t)
    if forbid_emojis and has_emoji(t):
        t = re.sub(r"[\p{Emoji_Presentation}]", "", t)
    return t


def ensure_period(text: str) -> str:
    """Ensure that ``text`` ends with a period.

    Args:
        text: Sentence fragment to finalize.

    Returns:
        The text without trailing whitespace and guaranteed to end with ``.``.
        Text already ending with ``.`` or the ellipsis character ``‚Ä¶`` is returned
        unchanged aside from trimming whitespace.

    Edge cases:
        If the input ends with other punctuation (e.g., ``!`` or ``?``), an extra
        period is appended.

    Example:
        ``ensure_period("done")`` ‚Üí ``"done."``
    """
    t = text.rstrip()
    return t if t.endswith((".", "‚Ä¶")) else (t + ".")


def fit_length(text: str, target: int) -> str:
    """Return a sentence containing exactly ``target`` words.

    The function trims or pads the input to reach the requested length and ensures
    the result ends with a period.

    Args:
        text: Source text.
        target: Desired number of words; should be a non-negative integer.

    Returns:
        A string with exactly ``target`` tokens, finalized with :func:`ensure_period`.

    Edge cases:
        - When the text is longer than ``target``, filler words (e.g., ``–¥—É–∂–µ`` or
          ``—Å–∞–º–µ``) are removed before truncating.
        - When shorter, the phrase "–î—ñ—é –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ i –∑–≤–∞–∂–µ–Ω–æ." is cycled to pad
          the sentence.
        - A ``target`` of zero produces just a period.

    Example:
        ``fit_length("—Å–ª–æ–≤–æ", 3)`` ‚Üí ``"—Å–ª–æ–≤–æ –î—ñ—é –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ."``
    """
    words = tokenize(text)
    if len(words) == target:
        return ensure_period(text)
    if len(words) > target:
        removable = {"–¥—É–∂–µ", "—Å–∞–º–µ", "—Ä–µ–∞–ª—å–Ω–æ", "–∑–∞–π–≤–µ", "–Ω–∞–¥–º—ñ—Ä–Ω–æ", "–¥–µ—â–æ", "—É–∫—Ä–∞–π"}
        filtered = [w for w in words if w.lower() not in removable]
        words = filtered if len(filtered) >= target else words
        words = words[:target]
        return ensure_period(" ".join(words))
    pad = ["–î—ñ—é", "–ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ", "—ñ", "–∑–≤–∞–∂–µ–Ω–æ."]  # noqa: RUF001
    i = 0
    while len(words) < target:
        words.append(pad[i % len(pad)])
        i += 1
    return ensure_period(" ".join(words))
